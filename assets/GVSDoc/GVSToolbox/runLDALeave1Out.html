<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of runLDALeave1Out</title>
  <meta name="keywords" content="runLDALeave1Out">
  <meta name="description" content="calculate leave 1 subject out accuracy for Bayes classifier with equal covariance">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">GVSToolbox</a> &gt; runLDALeave1Out.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for GVSToolbox&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>runLDALeave1Out
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>calculate leave 1 subject out accuracy for Bayes classifier with equal covariance</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function  [ percCorrect w predictedVsTrue] = runLDALeave1Out( featureVect, classLabels,numSamplesPerSubj, expLabels ) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> calculate leave 1 subject out accuracy for Bayes classifier with equal covariance
 
 syntax: [ percCorrect w ] = runLDALeave1Out( featureVect, classLabels, numSamplesPerSubj )
 
 Inputs:
   featureVect: (dim x numSamples) matrix of data
   classLabels: class labels, valued [0,1,2] for visualization, leave empty to
       not visualize. Originally, class 1 for learn, 0 for didn't learn,
       2 for remove because unclear
   numSamplesPerSubj: as name implies, for splitting up the data into
      leave 1 subject out cross validation
   expLabels: optional input usually returned by 'getLeave1OutLabels'
      function which specifies how to partition the data for leave 1
      subject out cross validation
 
 Outputs:
   percCorrect: percentage correctly classified by leave 1 subj out CV
   w: w vector returned by all the well labeled data
   predictedVsTrue: cell containing the [predeicted ; true] labels of the
       data for each fold of the cross validation
 
 Note, class 1 for learn, 0 for didn't learn, 2 for remove because unclear</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="getLeave1OutLabels.html" class="code" title="function trainTesTLabels = getLeave1OutLabels( numSamples, numPer1Subj )">getLeave1OutLabels</a>	get a struct for specifying folds of leave one out cross validation</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="exampleEasy.html" class="code" title="">exampleEasy</a>	Example for easy use</li><li><a href="simpleGUI.html" class="code" title="function varargout = simpleGUI(varargin)">simpleGUI</a>	SIMPLEGUI MATLAB code for simpleGUI.fig</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <span class="comment">% calculate leave 1 subject out accuracy for Bayes classifier with equal covariance</span>
0002 <span class="comment">%</span>
0003 <span class="comment">% syntax: [ percCorrect w ] = runLDALeave1Out( featureVect, classLabels, numSamplesPerSubj )</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% Inputs:</span>
0006 <span class="comment">%   featureVect: (dim x numSamples) matrix of data</span>
0007 <span class="comment">%   classLabels: class labels, valued [0,1,2] for visualization, leave empty to</span>
0008 <span class="comment">%       not visualize. Originally, class 1 for learn, 0 for didn't learn,</span>
0009 <span class="comment">%       2 for remove because unclear</span>
0010 <span class="comment">%   numSamplesPerSubj: as name implies, for splitting up the data into</span>
0011 <span class="comment">%      leave 1 subject out cross validation</span>
0012 <span class="comment">%   expLabels: optional input usually returned by 'getLeave1OutLabels'</span>
0013 <span class="comment">%      function which specifies how to partition the data for leave 1</span>
0014 <span class="comment">%      subject out cross validation</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% Outputs:</span>
0017 <span class="comment">%   percCorrect: percentage correctly classified by leave 1 subj out CV</span>
0018 <span class="comment">%   w: w vector returned by all the well labeled data</span>
0019 <span class="comment">%   predictedVsTrue: cell containing the [predeicted ; true] labels of the</span>
0020 <span class="comment">%       data for each fold of the cross validation</span>
0021 <span class="comment">%</span>
0022 <span class="comment">% Note, class 1 for learn, 0 for didn't learn, 2 for remove because unclear</span>
0023 
0024 
0025 <a name="_sub0" href="#_subfunctions" class="code">function  [ percCorrect w predictedVsTrue] = runLDALeave1Out( featureVect, classLabels, </a><span class="keyword">...</span>
0026                                     numSamplesPerSubj, expLabels )
0027 
0028 numSamples = size( featureVect,2);
0029 
0030 <span class="comment">% center and scale variables to unit variance</span>
0031 featureVect = featureVect - repmat( mean(featureVect,2), [1,numSamples] );
0032 featStdev = std( featureVect, 0, 2);
0033 featureVect( featStdev ~= 0,:) = featureVect( featStdev ~= 0,:)./repmat(featStdev(featStdev ~= 0), [1,numSamples]);
0034 <span class="comment">% featureVect = featureVect./repmat( std( featureVect, 0, 2)+.001, [1,numSamples]);</span>
0035 
0036 
0037 <span class="keyword">if</span> nargin &lt; 4 || isempty(expLabels)
0038     expLabels = <a href="getLeave1OutLabels.html" class="code" title="function trainTesTLabels = getLeave1OutLabels( numSamples, numPer1Subj )">getLeave1OutLabels</a>( numSamples, numSamplesPerSubj);
0039 <span class="comment">%     expLabels = balanceClasses( expLabels, classLabels );  % even out number samples in each class</span>
0040 <span class="keyword">end</span>
0041 numTrials = length(expLabels);
0042 
0043 classIndices = cell(2,1);
0044 numCorrect = 0;
0045 totalNumTest = 0;
0046 
0047 
0048 predictedVsTrue = cell( numTrials,1 );
0049 
0050 
0051 <span class="comment">% leave one subject out cross validation</span>
0052 <span class="keyword">for</span> i1 = 1:numTrials  
0053     <span class="comment">% training</span>
0054     
0055     trainLabels = classLabels(:,expLabels(i1).train);
0056     trainFeatures = featureVect(:,expLabels(i1).train);
0057     trainFeatures( :, trainLabels==2) = [];
0058     trainLabels( :, trainLabels==2) = [];
0059     
0060     testLabels = classLabels(:,expLabels(i1).test);
0061     testFeatures = featureVect(:,expLabels(i1).test);
0062     testFeatures( :, testLabels==2) = [];
0063     testLabels( :, testLabels==2) = [];
0064     
0065     <span class="keyword">if</span> ~isempty( testLabels)     
0066         classIndices{1} = find( trainLabels == 0); <span class="comment">% non learning</span>
0067         classIndices{2} = find( trainLabels == 1); <span class="comment">% learning</span>
0068                           
0069         meanVec = [ mean(trainFeatures(:,classIndices{1}),2), <span class="keyword">...</span>
0070                     mean(trainFeatures(:,classIndices{2}),2) ]; 
0071         Xtemp1 = [ trainFeatures(:,classIndices{1}) -  repmat( meanVec(:,1), [1,length(classIndices{1})])];                
0072         Xtemp2 = [ trainFeatures(:,classIndices{2}) -  repmat( meanVec(:,2), [1,length(classIndices{2})]) ];
0073         Sw = (Xtemp1*Xtemp1' + Xtemp2*Xtemp2')./length(trainLabels);
0074         
0075         <span class="comment">%Sw = cov( trainFeatures');</span>
0076         w = normc( pinv(Sw)*(meanVec(:,1) - meanVec(:,2)) );
0077 
0078         <span class="comment">% testing</span>
0079         projMeans = w'*meanVec;
0080         projectedData = w'*testFeatures;
0081         diffMatrix = sqrt((repmat(projMeans', [1,length(projectedData)]) <span class="keyword">...</span>
0082                         - repmat( projectedData,[length(projMeans),1]) ).^2);
0083         [c Idx ] = min( diffMatrix, [], 1);
0084         predictedLabels = Idx-1;  <span class="comment">% class labels are 0,1 , in that order (of means)</span>
0085 
0086         <span class="comment">%     predictedLabels</span>
0087         <span class="comment">%     sum(testLabels == predictedLabels );</span>
0088         tempNumCorrect = sum(testLabels == predictedLabels );
0089         numCorrect = numCorrect+ tempNumCorrect;
0090         numTest = length(predictedLabels);
0091         totalNumTest = totalNumTest+numTest;  
0092         fprintf( <span class="string">'Accuracy = %.2f, (%d/%d), %d Guessed 1; Train # class 1: %d, class 0: %d. \n'</span>, <span class="keyword">...</span>
0093             tempNumCorrect/numTest, tempNumCorrect,numTest, length(find(predictedLabels==1)), <span class="keyword">...</span>
0094             length(find(trainLabels==1)), length(find(trainLabels==0)));
0095         
0096         predictedVsTrue{i1} = [ predictedLabels; testLabels];
0097         
0098     <span class="keyword">end</span>
0099     
0100 <span class="keyword">end</span>
0101 percCorrect = numCorrect/totalNumTest; <span class="comment">%length(classLabels~=2);</span>
0102 <span class="comment">%----------------------------</span>
0103 
0104 <span class="comment">% find optimal w for all the data</span>
0105 featureVect( :, classLabels==2) = [];
0106 classLabels( :, classLabels==2) = [];
0107 classIndices{1} = find( classLabels == 0); <span class="comment">% non learning</span>
0108 classIndices{2} = find( classLabels == 1); <span class="comment">% learning</span>
0109 
0110 meanVec = [ mean(featureVect(:,classIndices{1}),2), <span class="keyword">...</span>
0111                     mean(featureVect(:,classIndices{2}),2) ];                 
0112 Xtemp1 = [ featureVect(:,classIndices{1}) -  repmat( meanVec(:,1), [1,length(classIndices{1})])];                
0113 Xtemp2 = [ featureVect(:,classIndices{2}) -  repmat( meanVec(:,2), [1,length(classIndices{2})]) ];
0114 Sw = (Xtemp1*Xtemp1' + Xtemp2*Xtemp2')./length(classLabels);
0115         
0116 w = pinv(Sw)*(meanVec(:,1) - meanVec(:,2));
0117 w = -w;
0118 
0119 
0120</pre></div>
<hr><address>Generated on Tue 01-Jul-2014 12:35:04 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>