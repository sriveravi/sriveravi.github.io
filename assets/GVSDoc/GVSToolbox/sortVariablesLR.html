<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of sortVariablesLR</title>
  <meta name="keywords" content="sortVariablesLR">
  <meta name="description" content="L1 penalized logistic regression ranking of variables">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">GVSToolbox</a> &gt; sortVariablesLR.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for GVSToolbox&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>sortVariablesLR
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>L1 penalized logistic regression ranking of variables</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [ bestVariables bestToWorst  ] = sortVariablesLR( featureVect, classLabels,topVarsToKeep, topVarsToSearch ) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> L1 penalized logistic regression ranking of variables
 
 syntax: [ bestVariables bestToWorst  ] = sortVariablesLR( featureVect, classLabels, ...
                 topVarsToKeep, topVarsToSearch )
 
 Inputs:
   featureVect: all the the data samples in (dim x numSamples)
   classLabels: all class labels (0 for not learned, 1 for learned, 2 unsure.  
      The ones labeled class 2 will not be used.
   topVarsToKeep: index of number of best variables to return
   topVarsToSearch: To find topVarsToKeep, we look at the most frequently
       top ranked variables within the (first:topVarsToSearch ) variables
       across all folds of leave subject out cross validation
 
 Outputs:
   bestVariables: indices of best variables to separate the classes
   bestToWorst: index ordering all the variables for all CV folds</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="findRedundancies.html" class="code" title="function unqIdx = findRedundancies( featVect  )">findRedundancies</a>	finds redundant variables for easy removal</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="exampleEasy.html" class="code" title="">exampleEasy</a>	Example for easy use</li><li><a href="simpleGUI.html" class="code" title="function varargout = simpleGUI(varargin)">simpleGUI</a>	SIMPLEGUI MATLAB code for simpleGUI.fig</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <span class="comment">% L1 penalized logistic regression ranking of variables</span>
0002 <span class="comment">%</span>
0003 <span class="comment">% syntax: [ bestVariables bestToWorst  ] = sortVariablesLR( featureVect, classLabels, ...</span>
0004 <span class="comment">%                 topVarsToKeep, topVarsToSearch )</span>
0005 <span class="comment">%</span>
0006 <span class="comment">% Inputs:</span>
0007 <span class="comment">%   featureVect: all the the data samples in (dim x numSamples)</span>
0008 <span class="comment">%   classLabels: all class labels (0 for not learned, 1 for learned, 2 unsure.</span>
0009 <span class="comment">%      The ones labeled class 2 will not be used.</span>
0010 <span class="comment">%   topVarsToKeep: index of number of best variables to return</span>
0011 <span class="comment">%   topVarsToSearch: To find topVarsToKeep, we look at the most frequently</span>
0012 <span class="comment">%       top ranked variables within the (first:topVarsToSearch ) variables</span>
0013 <span class="comment">%       across all folds of leave subject out cross validation</span>
0014 <span class="comment">%</span>
0015 <span class="comment">% Outputs:</span>
0016 <span class="comment">%   bestVariables: indices of best variables to separate the classes</span>
0017 <span class="comment">%   bestToWorst: index ordering all the variables for all CV folds</span>
0018 <span class="comment">%</span>
0019 
0020 <a name="_sub0" href="#_subfunctions" class="code">function [ bestVariables bestToWorst  ] = sortVariablesLR( featureVect, classLabels, </a><span class="keyword">...</span>
0021                 topVarsToKeep, topVarsToSearch )
0022 
0023 <span class="keyword">if</span> nargin &lt; 3 || isempty( topVarsToKeep)
0024     topVarsToKeep = 10;
0025 <span class="keyword">end</span>
0026 <span class="keyword">if</span> nargin &lt; 4 || isempty( topVarsToSearch )
0027     topVarsToSearch = topVarsToKeep;
0028 <span class="keyword">end</span>
0029 
0030 
0031 <span class="comment">% leave one subject out cross validation</span>
0032 [ dim numSamples] = size( featureVect);
0033 <span class="comment">% expLabels = getLeave1OutLabels( numSamples, numSamplesPerSubj);</span>
0034 numTrials = 1; <span class="comment">% length(expLabels);</span>
0035 bestToWorst = zeros( topVarsToSearch, numTrials);
0036 
0037 <span class="comment">% center and scale variables to unit variance</span>
0038 featureVect = featureVect - repmat( mean(featureVect,2), [1,numSamples] );
0039 featStdev = std( featureVect, 0, 2);
0040 featureVect( featStdev ~= 0,:) = featureVect( featStdev ~= 0,:)./repmat(featStdev(featStdev ~= 0), [1,numSamples]);
0041 <span class="comment">% featureVect = featureVect./repmat( std( featureVect, 0, 2)+.001, [1,numSamples]);</span>
0042 
0043 <span class="comment">% init some thing for LR</span>
0044 featureVect = [ones(numSamples,1) featureVect']'; <span class="comment">% Add Bias element to features (at top)</span>
0045 classLabels( classLabels == 0) = -1; <span class="comment">% Convert y to {-1,1} representation</span>
0046 baseLambda = ones(dim+1,1);  <span class="comment">% [ 1./(std( featureVect, 0, 2)+.001)]; % 15</span>
0047 options = struct(<span class="string">'verbose'</span>,0);
0048 
0049 
0050 <span class="keyword">for</span> i1 = 1; <span class="comment">%:numTrials</span>
0051     
0052     <span class="comment">% init weight and lambda scalar every trial</span>
0053     w = zeros( dim+1,1); <span class="comment">%  make sure it goes into while loop</span>
0054     lambdaScalar = 150;
0055     
0056     
0057     trainLabels = classLabels; <span class="comment">%(:,expLabels(i1).train);</span>
0058     trainFeatures = featureVect; <span class="comment">%(:,expLabels(i1).train);</span>
0059     trainFeatures( :, trainLabels==2) = [];
0060     trainLabels( :, trainLabels==2) = [];
0061     funObj = @(w)LogisticLoss(w,trainFeatures',trainLabels'); <span class="comment">% LR objective</span>
0062     
0063 <span class="comment">%     testLabels = classLabels(:,expLabels(i1).test);</span>
0064 <span class="comment">%     testFeatures = featureVect(:,expLabels(i1).test);</span>
0065 <span class="comment">%     testFeatures( :, testLabels==2) = [];</span>
0066 <span class="comment">%     testLabels( :, testLabels==2) = [];</span>
0067     
0068     <span class="comment">% do the tests on each feature</span>
0069     k1 = 0;
0070     <span class="keyword">while</span> nnz( w) &lt; topVarsToSearch &amp;&amp; k1 &lt; 500
0071         k1 = k1+1;
0072 
0073         lambda = lambdaScalar*baseLambda;
0074         lambda(1) = 0; <span class="comment">% Do not penalize bias variable</span>
0075         w = L1GeneralProjection(funObj,w,lambda, options );
0076         lambdaScalar = lambdaScalar/1.1;
0077         
0078         <span class="comment">% % testing</span>
0079         <span class="comment">% predictedLabels = sign(testFeatures'*w);</span>
0080         <span class="comment">% tempNumCorrect = sum(testLabels' == predictedLabels);</span>
0081     <span class="keyword">end</span>
0082     
0083     <span class="comment">% sort by most important, and put in the matrix</span>
0084     w(1) = [];
0085     [ temp bestToWorst] = sort( abs(w(:)), <span class="string">'descend'</span>);  
0086 <span class="comment">%     bestToWorst( :,i1) = wIdx(1:topVarsToSearch);</span>
0087     
0088 <span class="keyword">end</span>
0089 
0090 <span class="comment">% %feature selection</span>
0091 <span class="comment">% bestVariables = bestToWorst(:);</span>
0092 <span class="comment">% uniqVars = unique( sort(bestVariables) );</span>
0093 <span class="comment">% lengthList = zeros( length(uniqVars),1);</span>
0094 <span class="comment">% for i1 = 1:length(uniqVars)</span>
0095 <span class="comment">%    lengthList(i1) = length( find( bestVariables == uniqVars(i1)));</span>
0096 <span class="comment">% end</span>
0097 <span class="comment">% [ val idx] = sort( lengthList , 'descend');</span>
0098 
0099 
0100 <span class="comment">% remove redundancies</span>
0101 featureVect(1,:) = [];  <span class="comment">%to remove that unit offset</span>
0102 
0103 unqIdx = <a href="findRedundancies.html" class="code" title="function unqIdx = findRedundancies( featVect  )">findRedundancies</a>( featureVect(bestToWorst,:) );
0104 bestToWorst = bestToWorst(unqIdx);
0105 
0106 
0107 bestVariables = bestToWorst(1:min(topVarsToKeep, length(bestToWorst) ));
0108 
0109 
0110</pre></div>
<hr><address>Generated on Tue 01-Jul-2014 12:35:04 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>