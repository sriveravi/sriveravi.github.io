<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of sortVariablesNB</title>
  <meta name="keywords" content="sortVariablesNB">
  <meta name="description" content="Naive bayes ranking of variables (using CV accuracy criterion)">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">GVSToolbox</a> &gt; sortVariablesNB.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for GVSToolbox&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>sortVariablesNB
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>Naive bayes ranking of variables (using CV accuracy criterion)</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [ bestVariables, bestToWorst, accuracy ] = sortVariablesNB( featureVect, classLabels,numSamplesPerSubj, topVarsToKeep ) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Naive bayes ranking of variables (using CV accuracy criterion)
 
 syntax: [ bestVariables bestToWorst accuracy ] = sortVariablesNB( featureVect, classLabels, ...
                 numSamplesPerSubj, topVarsToKeep )
 
 Inputs:
   featureVect: all the the data samples in (dim x numSamples)
   classLabels: all class labels (0 for not learned, 1 for learned, 2 unsure.  
      The ones labeled class 2 will not be used.
   numSamplesPerSubj: featureVect assumed to be such that each subject has
      some number of samples (specified by each entry of numSamplesPerSubj),
      and they are grouped consecutively. This paramter is needed to do 
      the leave 1 subject out cross  validation.
   topVarsToKeep: index of number of best variables to return
 
 Outputs:
   bestVariables: indices of top variables to separate the classes
   bestToWorst: index ordering all the variables (not just the top)
   accuracy:  associated number correct for those indices</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="findRedundancies.html" class="code" title="function unqIdx = findRedundancies( featVect  )">findRedundancies</a>	finds redundant variables for easy removal</li><li><a href="getLeave1OutLabels.html" class="code" title="function trainTesTLabels = getLeave1OutLabels( numSamples, numPer1Subj )">getLeave1OutLabels</a>	get a struct for specifying folds of leave one out cross validation</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="exampleEasy.html" class="code" title="">exampleEasy</a>	Example for easy use</li><li><a href="simpleGUI.html" class="code" title="function varargout = simpleGUI(varargin)">simpleGUI</a>	SIMPLEGUI MATLAB code for simpleGUI.fig</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <span class="comment">% Naive bayes ranking of variables (using CV accuracy criterion)</span>
0002 <span class="comment">%</span>
0003 <span class="comment">% syntax: [ bestVariables bestToWorst accuracy ] = sortVariablesNB( featureVect, classLabels, ...</span>
0004 <span class="comment">%                 numSamplesPerSubj, topVarsToKeep )</span>
0005 <span class="comment">%</span>
0006 <span class="comment">% Inputs:</span>
0007 <span class="comment">%   featureVect: all the the data samples in (dim x numSamples)</span>
0008 <span class="comment">%   classLabels: all class labels (0 for not learned, 1 for learned, 2 unsure.</span>
0009 <span class="comment">%      The ones labeled class 2 will not be used.</span>
0010 <span class="comment">%   numSamplesPerSubj: featureVect assumed to be such that each subject has</span>
0011 <span class="comment">%      some number of samples (specified by each entry of numSamplesPerSubj),</span>
0012 <span class="comment">%      and they are grouped consecutively. This paramter is needed to do</span>
0013 <span class="comment">%      the leave 1 subject out cross  validation.</span>
0014 <span class="comment">%   topVarsToKeep: index of number of best variables to return</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% Outputs:</span>
0017 <span class="comment">%   bestVariables: indices of top variables to separate the classes</span>
0018 <span class="comment">%   bestToWorst: index ordering all the variables (not just the top)</span>
0019 <span class="comment">%   accuracy:  associated number correct for those indices</span>
0020 <span class="comment">%</span>
0021 
0022 <a name="_sub0" href="#_subfunctions" class="code">function [ bestVariables, bestToWorst, accuracy ] = sortVariablesNB( featureVect, classLabels, </a><span class="keyword">...</span>
0023                 numSamplesPerSubj, topVarsToKeep )
0024 
0025 <span class="keyword">if</span> nargin &lt; 4 || isempty( topVarsToKeep)
0026     topVarsToKeep = 10;
0027 <span class="keyword">end</span>
0028 
0029 <span class="comment">% leave one subject out cross validation</span>
0030 [ dim, numSamples] = size( featureVect);
0031 expLabels = <a href="getLeave1OutLabels.html" class="code" title="function trainTesTLabels = getLeave1OutLabels( numSamples, numPer1Subj )">getLeave1OutLabels</a>( numSamples, numSamplesPerSubj);
0032 numTrials = length(expLabels);
0033 accuracy = zeros( dim,1); <span class="comment">%,numTrials);</span>
0034 
0035 <span class="comment">% center and scale variables to unit variance</span>
0036 featureVect = featureVect - repmat( mean(featureVect,2), [1,numSamples] );
0037 featStdev = std( featureVect, 0, 2);
0038 featureVect( featStdev ~= 0,:) = featureVect( featStdev ~= 0,:)./repmat(featStdev(featStdev ~= 0), [1,numSamples]);
0039 <span class="comment">% featureVect = featureVect./repmat( std( featureVect, 0, 2)+.001, [1,numSamples]);</span>
0040 
0041 
0042 <span class="keyword">for</span> i1 = 1:numTrials 
0043     
0044     trainLabels = classLabels(:,expLabels(i1).train);
0045     trainFeatures = featureVect(:,expLabels(i1).train);
0046     trainFeatures( :, trainLabels==2) = [];
0047     trainLabels( :, trainLabels==2) = [];
0048     
0049     testLabels = classLabels(:,expLabels(i1).test);
0050     testFeatures = featureVect(:,expLabels(i1).test);
0051     testFeatures( :, testLabels==2) = [];
0052     testLabels( :, testLabels==2) = [];
0053     
0054     <span class="comment">% do the tests on each feature</span>
0055     <span class="keyword">for</span> i2 = 1:dim
0056         <span class="keyword">if</span> var( trainFeatures(i2,:)) &lt; 1e-5 || <span class="keyword">...</span>
0057             var( trainFeatures(i2,trainLabels==0))&lt; 1e-5 || <span class="keyword">...</span>
0058             var( trainFeatures(i2,trainLabels==1))&lt; 1e-5 ,        
0059             
0060                 <span class="comment">% do nothing</span>
0061                 <span class="comment">%accuracy(i2,i1) = 0;</span>
0062         <span class="keyword">else</span>
0063 <span class="comment">%             var( trainFeatures(i2,:))</span>
0064 <span class="comment">%             var( trainFeatures(i2,trainLabels==0))</span>
0065 <span class="comment">%             var( trainFeatures(i2,trainLabels==1))</span>
0066             
0067             nb = NaiveBayes.fit(trainFeatures(i2,:)', trainLabels', <span class="string">'Prior'</span>, <span class="string">'uniform'</span>);
0068             estimate = nb.predict(testFeatures(i2,:)');          
0069             accuracy(i2) = accuracy(i2) + sum( estimate == testLabels'); <span class="comment">%/length(testLabels);</span>
0070         <span class="keyword">end</span>
0071     <span class="keyword">end</span>
0072 <span class="comment">%      training is an N-by-D numeric matrix of training data. Rows of training</span>
0073 <span class="comment">%      correspond to observations; columns correspond to features. class is a</span>
0074 <span class="comment">%      classing variable for training (see Grouped Data) taking K distinct levels.</span>
0075 <span class="comment">%      Each element of class defines which class the corresponding row of training</span>
0076 <span class="comment">%      belongs to. training and class must have the same number of rows.</span>
0077 
0078 <span class="comment">% 'Prior' â€“ The prior probabilities for the classes, specified as one of the following:</span>
0079 <span class="comment">%</span>
0080 <span class="comment">% 'empirical' (default)    fit estimates the prior probabilities from the relative frequencies of the classes in training.</span>
0081 <span class="comment">% 'uniform'</span>
0082 
0083 <span class="keyword">end</span>
0084 
0085 <span class="comment">% % % % sort variables in order best to worst</span>
0086 <span class="comment">% % % [ accuracy bestToWorst] = sort( accuracy, 1, 'descend');</span>
0087 <span class="comment">% % % %feature selection</span>
0088 <span class="comment">% % % bestVariables = bestToWorst(1:topVarsToSearch,:);</span>
0089 <span class="comment">% % % bestVariables = bestVariables(:);</span>
0090 <span class="comment">% % % uniqVars = unique( sort(bestVariables) );</span>
0091 <span class="comment">% % % lengthList = zeros( length(uniqVars),1);</span>
0092 <span class="comment">% % % for i1 = 1:length(uniqVars)</span>
0093 <span class="comment">% % %    lengthList(i1) = length( find( bestVariables == uniqVars(i1)));</span>
0094 <span class="comment">% % % end</span>
0095 <span class="comment">% % % [ val idx] = sort( lengthList , 'descend');</span>
0096 
0097 
0098 <span class="comment">% sort variables in order best to worst</span>
0099 [ accuracy bestToWorst] = sort( accuracy, 1,<span class="string">'descend'</span>);
0100 
0101 <span class="comment">% remove redundancies</span>
0102 unqIdx = <a href="findRedundancies.html" class="code" title="function unqIdx = findRedundancies( featVect  )">findRedundancies</a>( featureVect( bestToWorst,:) );
0103 bestToWorst = bestToWorst(unqIdx);
0104 
0105 bestVariables = bestToWorst(1:min(topVarsToKeep, length(bestToWorst) ));</pre></div>
<hr><address>Generated on Tue 01-Jul-2014 12:35:04 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>